# Arachnida

A Python toolkit for web scraping and image metadata analysis, consisting of two main tools: **Spider** (web image scraper) and **Scorpion** (EXIF metadata extractor).

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Tools](#tools)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Dependencies](#dependencies)
- [Examples](#examples)
- [Project Structure](#project-structure)

## ğŸ•·ï¸ Overview

Arachnida is a cybersecurity-focused project that provides tools for:
- Web scraping and downloading images from websites
- Extracting and analyzing EXIF metadata from images
- Anonymizing images by removing metadata

This project is part of the 42 Cyber Pool curriculum and demonstrates skills in web scraping, image processing, and metadata analysis.

## ğŸ› ï¸ Tools

### Spider
A web scraper that downloads images from websites with support for recursive crawling.

### Scorpion
An EXIF metadata extractor that analyzes image files and optionally anonymizes them.

## ğŸ“¦ Installation

### Prerequisites
- Python 3.x
- `exiftool` (for anonymization feature)

### Setup

1. **Clone the repository:**
```bash
git clone <repository-url>
cd 42-CyberPool-Arachnida
```

2. **Create and activate virtual environment:**
```bash
python3 -m venv arachnide
source arachnide/bin/activate
```

3. **Install dependencies:**
```bash
# Spider dependencies
pip install requests beautifulsoup4

# Scorpion dependencies
pip install Pillow exif
```

4. **Install exiftool (for anonymization):**
```bash
sudo apt install libimage-exiftool-perl
```

5. **Create data directory:**
```bash
mkdir data
```

## ğŸš€ Usage

### Spider - Web Image Scraper

Download images from a website:

```bash
python3 spider.py [URL]
```

#### Options:
- `-r, --recursive`: Enable recursive download
- `-l, --length [DEPTH]`: Maximum depth level for recursive download (default: 5)
- `-p, --path [PATH]`: Download directory path (default: data/)
- `-d, --domain`: Stay on the same domain during recursive crawling

#### Examples:
```bash
# Basic image download
python3 spider.py https://example.com

# Recursive download with custom depth and path
python3 spider.py -r -l 3 -p ./images/ https://example.com

# Recursive download staying on same domain
python3 spider.py -r -d https://example.com
```

### Scorpion - EXIF Metadata Extractor

Analyze images in a directory:

```bash
python3 scorpion.py
```

#### Options:
- `-p, --path [PATH]`: Directory containing images (default: ./data/)
- `-a, --anonimize`: Remove EXIF data from images (creates anonymized copies)

#### Examples:
```bash
# Analyze images in default directory
python3 scorpion.py

# Analyze images in custom directory
python3 scorpion.py -p ./my_images/

# Analyze and anonymize images
python3 scorpion.py -a
```

## âœ¨ Features

### Spider Features:
- âœ… Downloads images in supported formats (JPG, JPEG, PNG, GIF, BMP)
- ğŸ”„ Recursive website crawling
- ğŸŒ Domain restriction option
- ğŸ“ Custom save directory
- ğŸ›¡ï¸ Error handling for network issues
- ğŸ“Š Progress indicators with emojis

### Scorpion Features:
- ğŸ“¸ Comprehensive EXIF data extraction
- ğŸ—‚ï¸ Categorized metadata display:
  - ğŸ“± Device information
  - â° DateTime metadata
  - ğŸ“¸ Camera settings
  - ğŸŒ GPS geolocation data
  - âš™ï¸ Technical specifications
- ğŸŒ GPS coordinate formatting (DMS and decimal)
- ğŸ—ºï¸ Google Maps links for GPS data
- ğŸ¨ Colorized terminal output
- ğŸ”’ Image anonymization (EXIF removal)

### Supported Image Formats:
- JPEG/JPG
- PNG
- GIF
- BMP

## ğŸ“Š Metadata Categories

Scorpion organizes EXIF data into the following categories:

1. **Device Information**: Camera make, model, lens specifications
2. **DateTime Information**: Creation dates, timestamps, timezone data
3. **Camera Settings**: Aperture, exposure, ISO, flash settings
4. **Image Specifications**: Dimensions, resolution, color space
5. **GPS Information**: Location coordinates, altitude, timestamps
6. **Technical Metadata**: EXIF version, compression, etc.

## ğŸ“ Project Structure

```
42-CyberPool-Arachnida/
â”œâ”€â”€ spider.py              # Web image scraper
â”œâ”€â”€ scorpion.py            # EXIF metadata extractor
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ .gitignore            # Git ignore rules
â”œâ”€â”€ en.subject.pdf        # Project subject (42 School)
â”œâ”€â”€ data/                 # Downloaded images directory
â””â”€â”€ arachnide/           # Python virtual environment
```

## ğŸ”§ Environment Management

**Activate virtual environment:**
```bash
source arachnide/bin/activate
```

**Deactivate virtual environment:**
```bash
deactivate
```

## âš ï¸ Important Notes

- Always respect website terms of service when scraping
- Be mindful of rate limiting and server load
- GPS data in images can reveal sensitive location information
- Anonymized images are created as separate files with `_anonymized` suffix
- The tool requires `exiftool` for the anonymization feature

## ğŸ¯ Educational Purpose

This project is designed for educational purposes as part of cybersecurity training. It demonstrates:
- Web scraping techniques and best practices
- Image metadata analysis for digital forensics
- Privacy implications of image metadata
- Python programming for security tools

## ğŸ“œ License

This project is part of the 42 School curriculum and follows their academic guidelines.